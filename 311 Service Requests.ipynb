{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sodapy import Socrata\n",
    "import re\n",
    "\n",
    "# Socrata specific \n",
    "socrata_domain = \"data.cityofnewyork.us\"\n",
    "socrata_token = \"F52GVJzdJf2mpjl7n17oXvzqF\" # should be an environment variable\n",
    "dataset_id = \"fhrw-4uyv\"\n",
    "\n",
    "# set up socrate client endpoint\n",
    "client = Socrata(socrata_domain, socrata_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieval and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complaints in 2017: 2445387\n"
     ]
    }
   ],
   "source": [
    "# get the total number of complaints made in 2017\n",
    "num_complaints_2017 = client.get(dataset_id,\n",
    "                    select=\"count(*)\",\n",
    "                    where=\"created_date between '2017-01-01T00:00:00.001' and '2017-12-31T23:59:59'\")[0]['count']\n",
    "\n",
    "print(\"Number of complaints in 2017: {}\".format(num_complaints_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get only the necessary fields and the exact amount of complaints made in 2017\n",
    "# starting from the 1st second into 2017 because there are about 50 complaints at time 00:00:00 and must be bogus\n",
    "results = client.get(dataset_id,\n",
    "                    select=\"unique_key, created_date, complaint_type, descriptor, incident_zip, borough, city\",\n",
    "                    where=\"created_date between '2017-01-01T00:00:00.001' and '2017-12-31T23:59:59'\",\n",
    "                    order=\"created_date ASC\",\n",
    "                    limit=num_complaints_2017)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "complaints_df_ = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complaints_df = complaints_df_.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean up zip codes by removing any null/invalid ones and truncating zip+4 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns only first 5 digits of any zipcode greater than 0\n",
    "def keep_five(zipc):\n",
    "    m = re.search('\\d{5}', zipc)\n",
    "    return m[0] if m and int(m[0]) > 0 else None\n",
    "\n",
    "# remove rows with null zip codes\n",
    "complaints_df = complaints_df[pd.notnull(complaints_df['incident_zip'])]\n",
    "\n",
    "# keep rows with valid zip codes and truncating 5+4 zips to 5 digits only\n",
    "complaints_df['incident_zip'] = complaints_df['incident_zip'].apply(keep_five)\n",
    "\n",
    "# remove rows with 'None' zip codes\n",
    "complaints_df = complaints_df[~complaints_df['incident_zip'].isin([None])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show number of complaints after cleaning zip codes\n",
    "complaints_before = complaints_df_.shape[0]\n",
    "complaints_after = complaints_df.shape[0]\n",
    "\n",
    "unspecified_boroughs_before = complaints_df_.borough.value_counts()['Unspecified']\n",
    "unspecified_boroughs_after = complaints_df.borough.value_counts()['Unspecified']\n",
    "\n",
    "print(\"Number of rows removed by cleaning zip codes (removing null and invalid): {}\".format(complaints_before - complaints_after))\n",
    "print(\"Number of unspecified boroughs removed by cleaning zip codes : {}\".format(unspecified_boroughs_before - unspecified_boroughs_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape website to get accurate zip code to borough info\n",
    "#### Use the zip codes found on the website to replace 311 data (5513 rows being updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use beautifulsoup to scrape webpage for zip codes and their boroughs\n",
    "# The website used only has 240 zip codes mapped to boroughs while the 311 data has ~600 unique zip codes\n",
    "# The website data is incomplete but still helpful in filtering \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# create a mapping for each zipcode and its corresponding borough\n",
    "zip_borough_web = {}\n",
    "\n",
    "# fetch website to scrape\n",
    "url = \"https://www.nycbynatives.com/nyc_info/new_york_city_zip_codes.php\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# create a BeautifulSoup object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "ziptable = soup.find('table')\n",
    "\n",
    "# iterate over all rows in table\n",
    "for row in ziptable.findAll('tr'):\n",
    "    data = row.findAll('td')\n",
    "    \n",
    "    # The structure of the website zip code table. each tr has 2 zips and boroughs\n",
    "    zip1 = data[0].text.strip()\n",
    "    borough1 = data[1].text.upper().strip()\n",
    "    zip2 = data[3].text.strip()\n",
    "    borough2 = data[4].text.upper().strip()\n",
    "    \n",
    "    if borough1 in 'STATEN':\n",
    "        borough1 += ' ISLAND'\n",
    "    \n",
    "    if borough2 in 'STATEN':\n",
    "        borough2 += ' ISLAND'\n",
    "    \n",
    "    # add both zips and boroughs to map\n",
    "    zip_borough_web[zip1] = borough1\n",
    "    zip_borough_web[zip2] = borough2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unspecified_boroughs_before = complaints_df['borough'].value_counts()['Unspecified']\n",
    "# replace the boroughs from 311 data with web data by zipcodes from web\n",
    "def replace_borough(row, zip_dict):\n",
    "    z = row['incident_zip']\n",
    "    if z in zip_dict:\n",
    "        return zip_dict[z]\n",
    "    else:\n",
    "        return row['borough']\n",
    "\n",
    "complaints_df['borough'] = complaints_df.apply(lambda row: replace_borough(row,zip_borough_web), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unspecified_boroughs_after = complaints_df['borough'].value_counts()['Unspecified']\n",
    "print(\"Total 'Unspecified' boroughs fixed with web data: {}\".format(unspecified_boroughs_before - unspecified_boroughs_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use311 data to clean\n",
    "#### Check which zip codes have more than one borough associated with it in the 311 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map zipcodes to boroughs\n",
    "# dictionary of zipcodes to list of boroughs\n",
    "zip_borough_311 = {}\n",
    "count = 0\n",
    "\n",
    "# if zipcode was seen before but the borough is new, add it to the list of boroughs for that zip\n",
    "# otherwise create new list with that borough\n",
    "for row in complaints_df[['borough','incident_zip']].itertuples():\n",
    "    z = row.incident_zip\n",
    "    b = row.borough\n",
    "    \n",
    "    # attach a new list to an unseen borough \n",
    "    if z not in zip_borough_311:\n",
    "        zip_borough_311[z] = []\n",
    "        \n",
    "    # reject if borough exists in list or is unspecified\n",
    "    if b not in zip_borough_311[z] and row.borough != 'Unspecified':\n",
    "        zip_borough_311[z].append(b)\n",
    "        count += 1\n",
    "        \n",
    "print(\"Number of rows with conflicting boroughs: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take just the first borough that in the list (could use a count for most frequent borough)\n",
    "zip_borough_311 =  {k:v[0] for (k,v) in zip_borough_311.items() if len(v) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace 'Unspecified' boroughs with mapped zipcodes from 311 data duplicates\n",
    "complaints_df['borough'] = complaints_df.apply(lambda row: replace_borough(row, zip_borough_311), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove remaining rows with 'Unspecified' boroughs that could not be determined from other data\n",
    "complaints_df = complaints_df.query(\"borough != 'Unspecified'\")\n",
    "\n",
    "print(\"Unspecified boroughs removed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 complaint types by borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the 10 most common overall complaint types\n",
    "top_10_complaint_types = complaints_df.complaint_type.value_counts()[:10]\n",
    "\n",
    "print(\"Number of unique complaint types in all boroughs:\\n{}\\n\".format(complaints_df.complaint_type.nunique()))\n",
    "print(\"Top 10 complaint types overall in all boroughs:\\n{}\".format(top_10_complaint_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create pivot table using the boroughs as the index and a count of each unique complaint type\n",
    "complaints_by_borough = complaints_df.pivot_table(index='borough', columns='complaint_type', aggfunc=len)\n",
    "\n",
    "# get a cross section of a column without a mutlilevel index (shouldn't matter which column is chosen)\n",
    "complaints_by_borough = complaints_by_borough.xs('city', axis=1, drop_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print just the top 10 complaint types \n",
    "complaints_by_borough[top_10_complaint_types.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify previous pivot table results\n",
    "# get the number of 10 most common overall complaint types PER BOROUGH\n",
    "\"\"\"\n",
    "# I only ran this to verify the output of the pivot table but it takes a while so...\n",
    "\n",
    "for borough in complaints_df.borough.unique():\n",
    "    for complaint in top_10_complaint_types.index:\n",
    "        count = len(complaints_df[(complaints_df['borough'] == borough) & (complaints_df['complaint_type'] == complaint)])\n",
    "        print(\"Borough: {}\\tType: {}\\tCount: {}\".format(borough, complaint, count))\n",
    "    print(\"\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 complaint types for top 10 most populous zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get 2010 census population by zipcode \n",
    "zipcode_df = pd.read_csv(\"https://s3.amazonaws.com/SplitwiseBlogJB/2010+Census+Population+By+Zipcode+(ZCTA).csv\")\n",
    "\n",
    "# renaming the columns for easier access\n",
    "zipcode_df.rename(columns = {'Zip Code ZCTA':'ZCTA', '2010 Census Population':'Population'}, inplace = True)\n",
    "\n",
    "# Filter the zipcode dataframe to include only NYC zipcodes (the ones in our 311 Service Request dataframe)\n",
    "zipcode_df = zipcode_df[zipcode_df['ZCTA'].isin(complaints_df.incident_zip.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort the zipcode dataframe by population in descending order\n",
    "zipcode_df.sort_values(by='Population', ascending=False, inplace=True)\n",
    "\n",
    "# print top 10 most populous zip codes\n",
    "zipcode_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# top 10 most populous zip codes (converted to string for indexing)\n",
    "top_10_most_populous_zips = [str(x) for x in zipcode_df['ZCTA'][:10].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create pivot table using the incident_zip as the index and a count of each unique complaint type\n",
    "complaints_by_zip = complaints_df.pivot_table(index='incident_zip', columns='complaint_type', aggfunc=len)\n",
    "\n",
    "# get a cross section of a column without a mutlilevel index (shouldn't matter which column is chosen)\n",
    "complaints_by_zip = complaints_by_zip.xs('borough', axis=1, drop_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the top 10 complaints in the top 10 most populous zip codes\n",
    "complaints_by_zip.loc[top_10_most_populous_zips][top_10_complaint_types.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which boroughs are the biggest \"complainers\" relative to the size of the population in 2017?\n",
    "# Calculate a complaint-index that adjusts for population of the borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data structures to hold calculated data\n",
    "population_by_borough = []\n",
    "num_complaints_by_borough = []\n",
    "\n",
    "# number of complaints by zip code\n",
    "num_complaints_by_zip = complaints_df['incident_zip'].value_counts().reset_index()\n",
    "num_complaints_by_zip.rename(columns = {'index':'ZCTA', 'incident_zip':'num_complaints'}, inplace = True)\n",
    "\n",
    "# iterate over boroughs\n",
    "for borough in complaints_df.borough.unique():\n",
    "    # get zips for borough\n",
    "    zips_of_borough = complaints_df.query('borough == @borough')['incident_zip']\n",
    "    \n",
    "    # sum population of each zipcode in the borough\n",
    "    population = np.sum(zipcode_df[zipcode_df['ZCTA'].isin(zips_of_borough)]['Population'])\n",
    "    population_by_borough.append( (borough, population) )\n",
    "    \n",
    "    # sum number of complaints by zipcode in the borough\n",
    "    num_complaints = np.sum(num_complaints_by_zip[num_complaints_by_zip['ZCTA'].isin(zips_of_borough)]['num_complaints'])\n",
    "    num_complaints_by_borough.append( (borough, num_complaints) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the population of each borough\n",
    "print(\"Population of each borough:\\n{}\".format(population_by_borough))\n",
    "print(\"Number of complaints for each borough:\\n{}\".format(num_complaints_by_borough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate population-adjusted complaint-index for each borough\n",
    "# The complaint-index measures the number of complaints in a borough compared to other boroughs in NYC\n",
    "\n",
    "# calcualate ratio of complaints to population size for each borough\n",
    "# get the population size of each borough relative to the total population of NYC\n",
    "# adjusted complaint-index is the ratio of complaints in the borough relative to borough population share in NYC\n",
    "\n",
    "total_nyc_population = np.sum(int(p[1]) for p in population_by_borough)\n",
    "\n",
    "complaint_index = []\n",
    "for i in range(len(population_by_borough)):\n",
    "    pct_complaints_for_borough = num_complaints_by_borough[i][1]/population_by_borough[i][1]\n",
    "    relative_population = population_by_borough[i][1]/total_nyc_population\n",
    "    \n",
    "    adjusted_complaint_index = pct_complaints_for_borough/relative_population\n",
    "    complaint_index.append((population_by_borough[i][0], adjusted_complaint_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort the list by largest complaint index and print\n",
    "complaint_index.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"The biggest complainers in descending order using complaint-index:\\n{}\".format(complaint_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
